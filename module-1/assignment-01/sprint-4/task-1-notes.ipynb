{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python394jvsc74a57bd0e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a",
   "display_name": "Python 3.9.4 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "digits = datasets.load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "clf = svm.SVC(gamma = 0.001, C=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([8])"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "clf.fit(digits.data[:-1],digits.target[:-1])\n",
    "clf.predict(digits.data[-1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng =np.random.RandomState(0)\n",
    "x = rng.rand(10,2000)\n",
    "x=np.array(x, dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "from sklearn import random_projection\n",
    "transformer=random_projection.GaussianRandomProjection()\n",
    "x_new=transformer.fit_transform(x)\n",
    "x_new.dtype"
   ]
  },
  {
   "source": [
    "Preprocess - Standartize"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "X_train = np.array([[ 1., -1.,  2.],\n",
    "                     [ 2.,  0.,  0.],\n",
    "                     [ 0.,  1., -1.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "scaler=preprocessing.StandardScaler().fit(X_train)\n",
    "scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([1.        , 0.        , 0.33333333])"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "scaler.mean_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0.81649658, 0.81649658, 1.24721913])"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "scaler.scale_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[ 0.        , -1.22474487,  1.33630621],\n",
       "       [ 1.22474487,  0.        , -0.26726124],\n",
       "       [-1.22474487,  1.22474487, -1.06904497]])"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "X_scaled=scaler.transform(X_train)\n",
    "X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([1., 1., 1.])"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "X_scaled.mean(axis=0)\n",
    "X_scaled.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Pipeline(steps=[('standardscaler', StandardScaler()),\n                ('logisticregression', LogisticRegression())])"
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.96"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "X,y = make_classification(random_state=42)\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y, random_state=42)\n",
    "pipe= make_pipeline(StandardScaler(), LogisticRegression())\n",
    "display(pipe.fit(X_train, y_train))\n",
    "\n",
    "pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0.5       , 0.        , 1.        ],\n",
       "       [1.        , 0.5       , 0.33333333],\n",
       "       [0.        , 1.        , 0.        ]])"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "X_train = np.array([[ 1., -1.,  2.],\n",
    "                    [ 2.,  0.,  0.],\n",
    "                    [ 0.,  1., -1.]])\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X_train_minmax = min_max_scaler.fit_transform(X_train)\n",
    "X_train_minmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0.5        0.5        0.33333333]\n[0.         0.5        0.33333333]\n"
     ]
    }
   ],
   "source": [
    "X_test=np.array([[-3.,-1.,4.]])\n",
    "X_test_minmax=min_max_scaler.transform(X_test)\n",
    "X_test_minmax\n",
    "print(min_max_scaler.scale_)\n",
    "print(min_max_scaler.min_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/lib/python3.9/site-packages/sklearn/preprocessing/_data.py:2612: UserWarning: n_quantiles (1000) is greater than the total number of samples (112). n_quantiles is set to n_samples.\n  warnings.warn(\"n_quantiles (%s) is greater than the total number \"\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([4.3, 5.1, 5.8, 6.5, 7.9])"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "X,y = datasets.load_iris(return_X_y = True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, random_state=0)\n",
    "quantile_transformer = preprocessing.QuantileTransformer(random_state = 0)\n",
    "X_train_trans = quantile_transformer.fit_transform(X_train)\n",
    "X_test_trans = quantile_transformer.transform(X_test)\n",
    "np.percentile(X_train[:,0], [0,25,50,75,100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0.        , 0.23873874, 0.50900901, 0.74324324, 1.        ])"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "np.percentile(X_train_trans[:,0],[0,25,50,75,100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([4.4  , 5.125, 5.75 , 6.175, 7.3  ])"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "np.percentile(X_test[:, 0], [0, 25, 50, 75, 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0.01351351, 0.25      , 0.47747748, 0.60472973, 0.94144144])"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "np.percentile(X_test_trans[:, 0], [0, 25, 50, 75, 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[1.28331718, 1.18092228, 0.84160269],\n",
       "       [0.94293279, 1.60960836, 0.3879099 ],\n",
       "       [1.35235668, 0.21715673, 1.09977091]])"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "pt = preprocessing.PowerTransformer(method=\"box-cox\", standardize=False)\n",
    "X_lognormal = np.random.RandomState(616).lognormal(size=(3,3))\n",
    "X_lognormal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[ 0.49024349,  0.17881995, -0.1563781 ],\n",
       "       [-0.05102892,  0.58863195, -0.57612415],\n",
       "       [ 0.69420009, -0.84857822,  0.10051454]])"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "pt.fit_transform(X_lognormal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/lib/python3.9/site-packages/sklearn/preprocessing/_data.py:2612: UserWarning: n_quantiles (1000) is greater than the total number of samples (150). n_quantiles is set to n_samples.\n  warnings.warn(\"n_quantiles (%s) is greater than the total number \"\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[4.3, 2. , 1. , 0.1],\n",
       "       [4.4, 2.2, 1.1, 0.1],\n",
       "       [4.4, 2.2, 1.2, 0.1],\n",
       "       [4.4, 2.2, 1.2, 0.1],\n",
       "       [4.5, 2.3, 1.3, 0.1],\n",
       "       [4.6, 2.3, 1.3, 0.2],\n",
       "       [4.6, 2.3, 1.3, 0.2],\n",
       "       [4.6, 2.3, 1.3, 0.2],\n",
       "       [4.6, 2.4, 1.3, 0.2],\n",
       "       [4.7, 2.4, 1.3, 0.2],\n",
       "       [4.7, 2.4, 1.3, 0.2],\n",
       "       [4.8, 2.5, 1.4, 0.2],\n",
       "       [4.8, 2.5, 1.4, 0.2],\n",
       "       [4.8, 2.5, 1.4, 0.2],\n",
       "       [4.8, 2.5, 1.4, 0.2],\n",
       "       [4.8, 2.5, 1.4, 0.2],\n",
       "       [4.9, 2.5, 1.4, 0.2],\n",
       "       [4.9, 2.5, 1.4, 0.2],\n",
       "       [4.9, 2.5, 1.4, 0.2],\n",
       "       [4.9, 2.6, 1.4, 0.2],\n",
       "       [4.9, 2.6, 1.4, 0.2],\n",
       "       [4.9, 2.6, 1.4, 0.2],\n",
       "       [5. , 2.6, 1.4, 0.2],\n",
       "       [5. , 2.6, 1.4, 0.2],\n",
       "       [5. , 2.7, 1.5, 0.2],\n",
       "       [5. , 2.7, 1.5, 0.2],\n",
       "       [5. , 2.7, 1.5, 0.2],\n",
       "       [5. , 2.7, 1.5, 0.2],\n",
       "       [5. , 2.7, 1.5, 0.2],\n",
       "       [5. , 2.7, 1.5, 0.2],\n",
       "       [5. , 2.7, 1.5, 0.2],\n",
       "       [5. , 2.7, 1.5, 0.2],\n",
       "       [5.1, 2.7, 1.5, 0.2],\n",
       "       [5.1, 2.8, 1.5, 0.2],\n",
       "       [5.1, 2.8, 1.5, 0.3],\n",
       "       [5.1, 2.8, 1.5, 0.3],\n",
       "       [5.1, 2.8, 1.5, 0.3],\n",
       "       [5.1, 2.8, 1.6, 0.3],\n",
       "       [5.1, 2.8, 1.6, 0.3],\n",
       "       [5.1, 2.8, 1.6, 0.3],\n",
       "       [5.1, 2.8, 1.6, 0.3],\n",
       "       [5.2, 2.8, 1.6, 0.4],\n",
       "       [5.2, 2.8, 1.6, 0.4],\n",
       "       [5.2, 2.8, 1.6, 0.4],\n",
       "       [5.2, 2.8, 1.7, 0.4],\n",
       "       [5.3, 2.8, 1.7, 0.4],\n",
       "       [5.4, 2.8, 1.7, 0.4],\n",
       "       [5.4, 2.9, 1.7, 0.4],\n",
       "       [5.4, 2.9, 1.9, 0.5],\n",
       "       [5.4, 2.9, 1.9, 0.6],\n",
       "       [5.4, 2.9, 3. , 1. ],\n",
       "       [5.4, 2.9, 3.3, 1. ],\n",
       "       [5.5, 2.9, 3.3, 1. ],\n",
       "       [5.5, 2.9, 3.5, 1. ],\n",
       "       [5.5, 2.9, 3.5, 1. ],\n",
       "       [5.5, 2.9, 3.6, 1. ],\n",
       "       [5.5, 2.9, 3.7, 1. ],\n",
       "       [5.5, 3. , 3.8, 1.1],\n",
       "       [5.5, 3. , 3.9, 1.1],\n",
       "       [5.6, 3. , 3.9, 1.1],\n",
       "       [5.6, 3. , 3.9, 1.2],\n",
       "       [5.6, 3. , 4. , 1.2],\n",
       "       [5.6, 3. , 4. , 1.2],\n",
       "       [5.6, 3. , 4. , 1.2],\n",
       "       [5.6, 3. , 4. , 1.2],\n",
       "       [5.7, 3. , 4. , 1.3],\n",
       "       [5.7, 3. , 4.1, 1.3],\n",
       "       [5.7, 3. , 4.1, 1.3],\n",
       "       [5.7, 3. , 4.1, 1.3],\n",
       "       [5.7, 3. , 4.2, 1.3],\n",
       "       [5.7, 3. , 4.2, 1.3],\n",
       "       [5.7, 3. , 4.2, 1.3],\n",
       "       [5.7, 3. , 4.2, 1.3],\n",
       "       [5.8, 3. , 4.3, 1.3],\n",
       "       [5.8, 3. , 4.3, 1.3],\n",
       "       [5.8, 3. , 4.4, 1.3],\n",
       "       [5.8, 3. , 4.4, 1.3],\n",
       "       [5.8, 3. , 4.4, 1.3],\n",
       "       [5.8, 3. , 4.4, 1.4],\n",
       "       [5.8, 3. , 4.5, 1.4],\n",
       "       [5.9, 3. , 4.5, 1.4],\n",
       "       [5.9, 3. , 4.5, 1.4],\n",
       "       [5.9, 3. , 4.5, 1.4],\n",
       "       [6. , 3.1, 4.5, 1.4],\n",
       "       [6. , 3.1, 4.5, 1.4],\n",
       "       [6. , 3.1, 4.5, 1.4],\n",
       "       [6. , 3.1, 4.5, 1.5],\n",
       "       [6. , 3.1, 4.6, 1.5],\n",
       "       [6. , 3.1, 4.6, 1.5],\n",
       "       [6.1, 3.1, 4.6, 1.5],\n",
       "       [6.1, 3.1, 4.7, 1.5],\n",
       "       [6.1, 3.1, 4.7, 1.5],\n",
       "       [6.1, 3.1, 4.7, 1.5],\n",
       "       [6.1, 3.1, 4.7, 1.5],\n",
       "       [6.1, 3.2, 4.7, 1.5],\n",
       "       [6.2, 3.2, 4.8, 1.5],\n",
       "       [6.2, 3.2, 4.8, 1.5],\n",
       "       [6.2, 3.2, 4.8, 1.5],\n",
       "       [6.2, 3.2, 4.8, 1.6],\n",
       "       [6.3, 3.2, 4.9, 1.6],\n",
       "       [6.3, 3.2, 4.9, 1.6],\n",
       "       [6.3, 3.2, 4.9, 1.6],\n",
       "       [6.3, 3.2, 4.9, 1.7],\n",
       "       [6.3, 3.2, 4.9, 1.7],\n",
       "       [6.3, 3.2, 5. , 1.8],\n",
       "       [6.3, 3.2, 5. , 1.8],\n",
       "       [6.3, 3.2, 5. , 1.8],\n",
       "       [6.3, 3.3, 5. , 1.8],\n",
       "       [6.4, 3.3, 5.1, 1.8],\n",
       "       [6.4, 3.3, 5.1, 1.8],\n",
       "       [6.4, 3.3, 5.1, 1.8],\n",
       "       [6.4, 3.3, 5.1, 1.8],\n",
       "       [6.4, 3.3, 5.1, 1.8],\n",
       "       [6.4, 3.4, 5.1, 1.8],\n",
       "       [6.4, 3.4, 5.1, 1.8],\n",
       "       [6.5, 3.4, 5.1, 1.8],\n",
       "       [6.5, 3.4, 5.2, 1.9],\n",
       "       [6.5, 3.4, 5.2, 1.9],\n",
       "       [6.5, 3.4, 5.3, 1.9],\n",
       "       [6.5, 3.4, 5.3, 1.9],\n",
       "       [6.6, 3.4, 5.4, 1.9],\n",
       "       [6.6, 3.4, 5.4, 2. ],\n",
       "       [6.7, 3.4, 5.5, 2. ],\n",
       "       [6.7, 3.4, 5.5, 2. ],\n",
       "       [6.7, 3.4, 5.5, 2. ],\n",
       "       [6.7, 3.5, 5.6, 2. ],\n",
       "       [6.7, 3.5, 5.6, 2. ],\n",
       "       [6.7, 3.5, 5.6, 2.1],\n",
       "       [6.7, 3.5, 5.6, 2.1],\n",
       "       [6.7, 3.5, 5.6, 2.1],\n",
       "       [6.8, 3.5, 5.6, 2.1],\n",
       "       [6.8, 3.6, 5.7, 2.1],\n",
       "       [6.8, 3.6, 5.7, 2.1],\n",
       "       [6.9, 3.6, 5.7, 2.2],\n",
       "       [6.9, 3.6, 5.8, 2.2],\n",
       "       [6.9, 3.7, 5.8, 2.2],\n",
       "       [6.9, 3.7, 5.8, 2.3],\n",
       "       [7. , 3.7, 5.9, 2.3],\n",
       "       [7.1, 3.8, 5.9, 2.3],\n",
       "       [7.2, 3.8, 6. , 2.3],\n",
       "       [7.2, 3.8, 6. , 2.3],\n",
       "       [7.2, 3.8, 6.1, 2.3],\n",
       "       [7.3, 3.8, 6.1, 2.3],\n",
       "       [7.4, 3.8, 6.1, 2.3],\n",
       "       [7.6, 3.9, 6.3, 2.4],\n",
       "       [7.7, 3.9, 6.4, 2.4],\n",
       "       [7.7, 4. , 6.6, 2.4],\n",
       "       [7.7, 4.1, 6.7, 2.5],\n",
       "       [7.7, 4.2, 6.7, 2.5],\n",
       "       [7.9, 4.4, 6.9, 2.5]])"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "qunatlie_transformer=preprocessing.QuantileTransformer(output_distribution='normal',random_state = 0)\n",
    "X_trans = quantile_transformer.fit_transform(X)\n",
    "quantile_transformer.quantiles_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[ 0.40824829, -0.40824829,  0.81649658],\n",
       "       [ 1.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.70710678, -0.70710678]])"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "X = [[ 1., -1.,  2.],\n",
    "     [ 2.,  0.,  0.],\n",
    "     [ 0.,  1., -1.]]\n",
    "X_normalized = preprocessing.normalize(X, norm='l2')\n",
    "X_normalized    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Normalizer()"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "normalizer = preprocessing.Normalizer().fit(X)\n",
    "normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[-0.70710678,  0.70710678,  0.        ]])"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "normalizer.transform([[-1.,1.,0.]])"
   ]
  },
  {
   "source": [
    "# Encoding categorical values"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "OrdinalEncoder()"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "enc = preprocessing.OrdinalEncoder()\n",
    "X = [['male', 'from US', 'uses Safari'], ['female', 'from Europe', 'uses Firefox']]\n",
    "enc.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0., 1., 1.]])"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "enc.transform([['female', 'from US', 'uses Safari']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "OneHotEncoder(categories=[['female', 'male'],\n",
       "                          ['from Africa', 'from Asia', 'from Europe',\n",
       "                           'from US'],\n",
       "                          ['uses Chrome', 'uses Firefox', 'uses IE',\n",
       "                           'uses Safari']])"
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "genders = ['female', 'male']\n",
    "locations = ['from Africa', 'from Asia', 'from Europe', 'from US']\n",
    "browsers = ['uses Chrome', 'uses Firefox', 'uses IE', 'uses Safari']\n",
    "enc=preprocessing.OneHotEncoder(categories=[genders,locations,browsers])\n",
    "enc.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 1., 0., 0., 1., 0., 0., 0.]])"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "enc.transform([['female', 'from Asia', 'uses Chrome']]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0., 0.]])"
      ]
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "enc2=preprocessing.OneHotEncoder(handle_unknown='ignore')\n",
    "enc2.fit(X)\n",
    "enc2.transform([['female', 'from Asia', 'uses Chrome']]).toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[array(['female', 'male'], dtype=object),\n",
       " array(['Asia', 'Europe', 'US'], dtype=object),\n",
       " array(['Chrome', 'Firefox', 'Safari'], dtype=object)]"
      ]
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "source": [
    "X = [['male', 'US', 'Safari'],\n",
    "     ['female', 'Europe', 'Firefox'],\n",
    "     ['female', 'Asia', 'Chrome']]\n",
    "drop_enc=preprocessing.OneHotEncoder(drop='if_binary').fit(X)\n",
    "drop_enc.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 1., 0., 0., 1.],\n",
       "       [0., 0., 1., 0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0., 1., 0., 0.]])"
      ]
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "source": [
    "drop_enc.transform(X).toarray()"
   ]
  },
  {
   "source": [
    "# Discretization"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[ -3., 5., 15 ],\n",
    "              [  0., 6., 14 ],\n",
    "              [  6., 3., 11 ]])\n",
    "est = preprocessing.KBinsDiscretizer(n_bins=[3,2,2], encode='ordinal').fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0., 1., 1.],\n",
       "       [1., 1., 1.],\n",
       "       [2., 0., 0.]])"
      ]
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "source": [
    "est.transform(X)"
   ]
  },
  {
   "source": [
    "# Generating polynomial features"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [2, 3],\n",
       "       [4, 5]])"
      ]
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "X=np.arange(6).reshape(3,2)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  1.,  0.,  0.,  1.],\n",
       "       [ 1.,  2.,  3.,  4.,  6.,  9.],\n",
       "       [ 1.,  4.,  5., 16., 20., 25.]])"
      ]
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "source": [
    "poly=PolynomialFeatures(2)\n",
    "poly.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[0 1 2]\n [3 4 5]\n [6 7 8]]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[  1.,   0.,   1.,   2.,   0.,   0.,   0.,   1.,   2.,   4.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   1.,   2.,   4.,   8.],\n",
       "       [  1.,   3.,   4.,   5.,   9.,  12.,  15.,  16.,  20.,  25.,  27.,\n",
       "         36.,  45.,  48.,  60.,  75.,  64.,  80., 100., 125.],\n",
       "       [  1.,   6.,   7.,   8.,  36.,  42.,  48.,  49.,  56.,  64., 216.,\n",
       "        252., 288., 294., 336., 384., 343., 392., 448., 512.]])"
      ]
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "source": [
    "X = np.arange(9).reshape(3,3)\n",
    "print(X)\n",
    "poly=PolynomialFeatures(degree = 3, interaction_only=False)\n",
    "poly.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0.        , 0.69314718],\n",
       "       [1.09861229, 1.38629436]])"
      ]
     },
     "metadata": {},
     "execution_count": 48
    }
   ],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer\n",
    "transformer = FunctionTransformer(np.log1p, check_inverse = True,validate = True)\n",
    "X = np.array([[0,1],[2,3]])\n",
    "transformer.fit(X)\n",
    "transformer.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"error\", message=\".*check_inverse*\", category = UserWarning, append=False)"
   ]
  }
 ]
}